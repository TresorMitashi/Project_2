{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DESCRIPTION OF THE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the project appears to be to build a machine learning pipeline that can classify messages into one or more categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project is divided into three main parts:\n",
    "\n",
    "1. ETL Pipeline (Extract, Transform, Load):\n",
    "The process_data.py file contains Python code to create an ETL pipeline.\n",
    "The goal is to retrieve emergency text messages and their classifications from a given dataset, clean the data, and store it in an SQLite database.\n",
    "2. ML Pipeline:\n",
    "The train_classifier.py file contains Python code to create an ML pipeline.\n",
    "The dataset is divided into a training and test set.\n",
    "A sklearn machine learning pipeline is created using NLTK (Natural Language Toolkit), incorporating hyperparameter optimization via Grid Search.\n",
    "The ML model uses the AdaBoost algorithm for multi-output classification to predict the classification of text messages.\n",
    "3. Web App:\n",
    "The web application allows users to enter an emergency message.\n",
    "Users can view the categories of the message in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. INSTALLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We installed Anaconda and python 3.x.x for using packages installed for EDA or modeling.\n",
    "\n",
    "Connect to Python prompt and with the help of 'pip install' install :\n",
    "\n",
    "flask, pickle, plotly, nltk, SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. INSTRUCTIONS FOR RUNNING THE SCRIPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To follow these steps, you need to open a command prompt or terminal and navigate to the directory where your project files are located. Then, you can execute the commands provided.\n",
    "\n",
    "Here's how you can do it step by step:\n",
    "\n",
    "1. Launch the ETL Pipeline:\n",
    "Open a command prompt or terminal.\n",
    "Navigate to the directory where your project files are located.\n",
    "Execute the following command to run the ETL pipeline:\n",
    "python data/process_data.py data/messages.csv data/categories.csv data/Disaster_Clean.db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Launch the ML Pipeline and Create the Model:\n",
    "After the ETL pipeline has finished processing the data and creating the SQLite database, execute the following command to run the ML pipeline and create the model:\n",
    "python models/train_classifier.py data/Disaster_Clean.db models/classifier.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Launch the Server Web:\n",
    "Navigate to the \"app\" folder in your project directory.\n",
    "Execute the following command to run the Flask web server:\n",
    "python run.py\n",
    "\n",
    "Once you see the confirmation message that the Flask server is running, open your web browser and go to http://127.0.0.1:3001 to access the web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
